{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f2393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Any, Optional\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fbc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wce_frame_onset import *\n",
    "from dataloader_wce import *\n",
    "\n",
    "from utils import set_seed, get_device\n",
    "\n",
    "# Add project root to sys.path\n",
    "project_root = Path(os.getcwd())\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd28ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Metrics Tracker (Supports Subject-wise ERR)\n",
    "# -----------------------------------------------------------------------------\n",
    "def compute_MAPE(y_pred, y_true, eps=1e-8):\n",
    "    # Mean Absolute Percentage Error\n",
    "    # handle zeros in y_true by clipping or adding eps\n",
    "    y_true_clamped = np.maximum(y_true, 1.0)\n",
    "    abs_err = np.abs(y_pred - y_true)\n",
    "    return np.mean(abs_err / y_true_clamped) * 100.0\n",
    "\n",
    "def compute_MPE(y_pred, y_true, eps=1e-8):\n",
    "    # Mean Percentage Error\n",
    "    y_true_clamped = np.maximum(y_true, 1.0)\n",
    "    err = (y_pred - y_true)\n",
    "    return np.mean(err / y_true_clamped) * 100.0\n",
    "\n",
    "class MetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.losses = []\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "        self.subjects = []\n",
    "        self.sample_count = 0\n",
    "    \n",
    "    def update(self, loss_val, y_true_batch, y_pred_batch, subject_batch=None):\n",
    "        loss_val = float(loss_val) \n",
    "        batch_size = len(y_true_batch)\n",
    "        self.losses.append(loss_val * batch_size)\n",
    "        self.sample_count += batch_size\n",
    "        \n",
    "        if isinstance(y_true_batch, torch.Tensor):\n",
    "            y_true_batch = y_true_batch.detach().cpu().numpy()\n",
    "        if isinstance(y_pred_batch, torch.Tensor):\n",
    "            y_pred_batch = y_pred_batch.detach().cpu().numpy()\n",
    "            \n",
    "        self.y_true.append(y_true_batch)\n",
    "        self.y_pred.append(y_pred_batch)\n",
    "        \n",
    "        if subject_batch is not None:\n",
    "            # subject_batch should be list or numpy array of strings/ids\n",
    "            self.subjects.append(subject_batch)\n",
    "            \n",
    "    def result(self):\n",
    "        avg_loss = np.sum(self.losses) / max(1, self.sample_count)\n",
    "        if not self.y_true:\n",
    "            return {\"loss\": avg_loss, \"mpe\": 0.0, \"mape\": 0.0, \"err_median\": 0.0}\n",
    "\n",
    "        y_t = np.concatenate(self.y_true)\n",
    "        y_p = np.concatenate(self.y_pred)\n",
    "        \n",
    "        # 1. Basic Micro Metrics (Global)\n",
    "        mape = compute_MAPE(y_p, y_t)\n",
    "        mpe = compute_MPE(y_p, y_t)\n",
    "        \n",
    "        res = {\n",
    "            \"loss\": avg_loss,\n",
    "            \"mpe\": mpe,      # micro MPE\n",
    "            \"mape\": mape,    # micro MAPE\n",
    "            \"err_median\": 0.0 # default\n",
    "        }\n",
    "        \n",
    "        # 2. Subject-wise Aggregation (ERR)\n",
    "        if self.subjects:\n",
    "            subjs = np.concatenate(self.subjects)\n",
    "            df = pd.DataFrame({\"subj\": subjs, \"pred\": y_p, \"true\": y_t})\n",
    "            \n",
    "            # Group by Subject -> Sum Counts\n",
    "            grp = df.groupby(\"subj\", sort=False).agg({\"pred\": \"sum\", \"true\": \"sum\"})\n",
    "            \n",
    "            # ERR Calculation: |Pred - True| / max(True, 1.0)\n",
    "            err_per_subject = (grp[\"pred\"] - grp[\"true\"]).abs() / np.clip(grp[\"true\"], 1.0, None)\n",
    "            \n",
    "            res[\"err_mean\"] = float(err_per_subject.mean())\n",
    "            res[\"err_median\"] = float(err_per_subject.median()) # â˜… Key Metric\n",
    "            res[\"err_std\"] = float(err_per_subject.std(ddof=0))\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf71ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Utils for Optimizer/Scheduler (Simplified from pipeline)\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def sanitize_optimizer_cfg(cfg):\n",
    "    # Remove basic types that are not needed for optimizer kwargs\n",
    "    return {k: v for k, v in cfg.items() if k not in [\"name\", \"scheme\"]}\n",
    "\n",
    "def build_optimizer(model, cfg):\n",
    "    opt_name = cfg.get(\"name\", \"AdamW\")\n",
    "    opt_kwargs = sanitize_optimizer_cfg(cfg)\n",
    "    if opt_name == \"AdamW\":\n",
    "        return optim.AdamW(model.parameters(), **opt_kwargs)\n",
    "    elif opt_name == \"Adam\":\n",
    "        return optim.Adam(model.parameters(), **opt_kwargs)\n",
    "    else:\n",
    "        # fallback\n",
    "        return optim.AdamW(model.parameters(), **opt_kwargs)\n",
    "\n",
    "def get_loss_config(train_cfg):\n",
    "    \"\"\"Extract loss configuration from train_cfg\"\"\"\n",
    "    return {\n",
    "        \"frame_weight\": train_cfg.get(\"loss_weights\", {}).get(\"frame\", 1.0),\n",
    "        \"count_weight\": train_cfg.get(\"loss_weights\", {}).get(\"count\", 0.01),\n",
    "        \"count_loss_type\": train_cfg.get(\"count_loss_type\", \"l2\"),\n",
    "        \"pos_weight\": train_cfg.get(\"pos_weight\", None),\n",
    "    }\n",
    "\n",
    "def get_scheduler(optimizer, name, epochs=None, steps_per_epoch=None, total_steps=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Simplified factory supporting only 'cosine_warmup'.\n",
    "    Returns (scheduler, mode='batch')\n",
    "    \"\"\"\n",
    "    if name != \"cosine_warmup\":\n",
    "        print(f\"[Warning] Scheduler '{name}' is not supported in this simplified script. Returning None.\")\n",
    "        return None, None\n",
    "\n",
    "    # 1. Infer Total Steps\n",
    "    if total_steps is None:\n",
    "        if epochs is not None and steps_per_epoch is not None:\n",
    "            total_steps = int(epochs) * int(steps_per_epoch)\n",
    "        else:\n",
    "            raise ValueError(\"Scheduler needs total_steps or (epochs and steps_per_epoch)\")\n",
    "\n",
    "    # 2. Parse Args (default values provided if missing)\n",
    "    warmup_steps = kwargs.get(\"warmup_steps\", 10200)\n",
    "    min_lr = kwargs.get(\"min_lr\", 0.0333)\n",
    "\n",
    "    # 3. Define Lambda\n",
    "    def lr_lambda(step: int) -> float:\n",
    "        # Phase 1: Linear Warmup\n",
    "        if step < warmup_steps:\n",
    "            return float(step) / float(max(1, warmup_steps))\n",
    "        \n",
    "        # Phase 2: Cosine Decay\n",
    "        progress = float(step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
    "        progress = min(1.0, max(0.0, progress)) # Clamp 0~1\n",
    "        \n",
    "        return 0.5 * (1.0 + math.cos(math.pi * progress)) * (1.0 - min_lr) + min_lr\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda), \"batch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf11f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Trainer\n",
    "# -----------------------------------------------------------------------------\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_loader, val_loader, args, train_cfg, opt_cfg, scheduler_cfg=None):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.args = args\n",
    "        self.train_cfg = train_cfg\n",
    "        self.device = torch.device(train_cfg.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        sanitized_opt_cfg = sanitize_optimizer_cfg(opt_cfg)\n",
    "        self.optimizer = build_optimizer(self.model, sanitized_opt_cfg)\n",
    "\n",
    "        # Scheduler\n",
    "        self.scheduler = None\n",
    "        self.scheduler_mode = None\n",
    "        \n",
    "        if scheduler_cfg and scheduler_cfg.get(\"scheme\", \"none\").lower() != \"none\":\n",
    "            self.scheduler, self.scheduler_mode = get_scheduler(\n",
    "                self.optimizer,\n",
    "                name=scheduler_cfg[\"scheme\"],\n",
    "                epochs=self.train_cfg.get(\"num_epochs\"),              \n",
    "                steps_per_epoch=self.train_cfg.get(\"steps_per_epoch\", len(train_loader)),\n",
    "                total_steps=self.train_cfg.get(\"steps_per_epoch\", len(train_loader))*self.train_cfg.get(\"num_epochs\"),\n",
    "                **{k: v for k, v in scheduler_cfg.items() if k != \"scheme\"}\n",
    "            )\n",
    "\n",
    "        # GradScaler\n",
    "        self.scaler = torch.amp.GradScaler('cuda', enabled=(self.device.type == 'cuda'))\n",
    "        \n",
    "        # Loss config\n",
    "        self.loss_cfg = get_loss_config(self.train_cfg)\n",
    "        \n",
    "    def train_step(self, batch):\n",
    "        self.model.train()\n",
    "        feats, lengths, labels, counts_gt = batch\n",
    "        feats = feats.to(self.device)\n",
    "        lengths = lengths.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        counts_gt = counts_gt.to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad(set_to_none=True)\n",
    "        amp_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "        \n",
    "        with torch.amp.autocast(device_type=self.device.type, dtype=amp_dtype, enabled=self.scaler.is_enabled()):\n",
    "            outputs = self.model(feats, lengths)\n",
    "            loss = frame_onset_bce_count_mix(\n",
    "                out_dict=outputs,\n",
    "                frame_targets=labels,\n",
    "                lengths=lengths,\n",
    "                pos_weight=self.loss_cfg[\"pos_weight\"],\n",
    "                frame_weight=self.loss_cfg[\"frame_weight\"],\n",
    "                count_weight=self.loss_cfg[\"count_weight\"],\n",
    "                count_loss_type=self.loss_cfg[\"count_loss_type\"]\n",
    "            )\n",
    "        \n",
    "        self.scaler.scale(loss).backward()\n",
    "        self.scaler.step(self.optimizer)\n",
    "        self.scaler.update()\n",
    "        \n",
    "        # Scheduler Step (Batch)\n",
    "        if self.scheduler and self.scheduler_mode == 'batch':\n",
    "            self.scheduler.step()\n",
    "        \n",
    "        # Return loss and predictions for metrics\n",
    "        pred_count = outputs.get('count', outputs['frame_logits'].sigmoid().sum(dim=1))\n",
    "        return loss.item(), counts_gt, pred_count\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def validation_step(self, batch):\n",
    "        self.model.eval()\n",
    "        feats, lengths, labels, counts_gt = batch\n",
    "        feats = feats.to(self.device)\n",
    "        lengths = lengths.to(self.device)\n",
    "        labels = labels.to(self.device)\n",
    "        counts_gt = counts_gt.to(self.device)\n",
    "        \n",
    "        outputs = self.model(feats, lengths)\n",
    "        loss = frame_onset_bce_count_mix(\n",
    "            out_dict=outputs,\n",
    "            frame_targets=labels,\n",
    "            lengths=lengths,\n",
    "            pos_weight=self.loss_cfg[\"pos_weight\"],\n",
    "            frame_weight=self.loss_cfg[\"frame_weight\"],\n",
    "            count_weight=self.loss_cfg[\"count_weight\"],\n",
    "            count_loss_type=self.loss_cfg[\"count_loss_type\"]\n",
    "        )\n",
    "        \n",
    "        pred_count = outputs.get('count', outputs['frame_logits'].sigmoid().sum(dim=1))\n",
    "        return loss.item(), counts_gt, pred_count\n",
    "\n",
    "    def fit(self, num_epochs=100, early_stop_metric=\"val_err_median\", patience=10, min_delta=0.01):\n",
    "        best_metric = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Check if dataset has 'speaker_id' for subject-wise metrics\n",
    "        has_speaker_id = False\n",
    "        if hasattr(self.val_loader.dataset, 'meta') and 'speaker_id' in self.val_loader.dataset.meta.columns:\n",
    "            has_speaker_id = True\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Training\n",
    "            train_tracker = MetricsTracker()\n",
    "            pbar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
    "            \n",
    "            for batch in pbar:\n",
    "                loss_val, y_true, y_pred = self.train_step(batch)\n",
    "                train_tracker.update(loss_val, y_true, y_pred) # Train doesn't usually need subject info\n",
    "                pbar.set_postfix({'loss': loss_val})\n",
    "            \n",
    "            # Scheduler Step (Epoch)\n",
    "            if self.scheduler and self.scheduler_mode == 'epoch':\n",
    "                self.scheduler.step()\n",
    "                \n",
    "            train_res = train_tracker.result()\n",
    "            \n",
    "            # Validation\n",
    "            val_tracker = MetricsTracker()\n",
    "            sample_cursor = 0\n",
    "            \n",
    "            for batch in tqdm(self.val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\"):\n",
    "                loss_val, y_true, y_pred = self.validation_step(batch) \n",
    "                \n",
    "                subjects = []\n",
    "                if has_speaker_id:\n",
    "                    batch_size = len(y_true)\n",
    "                    dataset_obj = self.val_loader.dataset\n",
    "                    \n",
    "                    for j in range(batch_size):\n",
    "                        curr_idx = sample_cursor + j\n",
    "                        if hasattr(dataset_obj, 'indices'):\n",
    "                            real_idx = dataset_obj.indices[curr_idx]\n",
    "                            subj = dataset_obj.dataset.get_subject_id(real_idx)\n",
    "                        else:\n",
    "                            subj = dataset_obj.get_subject_id(curr_idx)\n",
    "                        subjects.append(subj)\n",
    "                    sample_cursor += batch_size\n",
    "                else:\n",
    "                    subjects = None\n",
    "                \n",
    "                val_tracker.update(loss_val, y_true, y_pred, subjects)\n",
    "            \n",
    "            val_res = val_tracker.result()\n",
    "\n",
    "            # Scheduler Step (Metric) - e.g. ReduceLROnPlateau\n",
    "            if self.scheduler and self.scheduler_mode == 'metric':\n",
    "                self.scheduler.step(val_res['loss'])\n",
    "\n",
    "            print(f\"\\n[Epoch {epoch+1}]\")\n",
    "            print(f\"  Train -> Loss: {train_res['loss']:.4f} | MPE: {train_res['mpe']:.2f}% | MAPE: {train_res['mape']:.2f}%\")\n",
    "            print(f\"  Valid -> Loss: {val_res['loss']:.4f} | MPE: {val_res['mpe']:.2f}% | MAPE: {val_res['mape']:.2f}%\")\n",
    "            \n",
    "            # Early Stopping & Checkpoint\n",
    "            current_val = float('inf')\n",
    "            if early_stop_metric == \"val_err_median\":\n",
    "                current_val = val_res.get('err_median', val_res['mape']) # Fallback to MAPE if no err_median\n",
    "            elif early_stop_metric == \"val_loss\":\n",
    "                current_val = val_res['loss']\n",
    "            elif early_stop_metric == \"val_mape\":\n",
    "                current_val = val_res['mape']\n",
    "            \n",
    "            if current_val < best_metric - min_delta:\n",
    "                best_metric = current_val\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), \"model_best.pt\")\n",
    "                print(f\"  >> New Best Model saved! ({early_stop_metric}={current_val:.4f})\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"  >> Early stopping triggered! No improvement for {patience} epochs.\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a92827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Config\n",
    "class ArgsMock:\n",
    "    pass\n",
    "\n",
    "def load_data_from_args(pt_path, csv_path):\n",
    "    print(f\"Loading meta: {csv_path}\")\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"{csv_path} not found.\")\n",
    "    meta = pd.read_csv(csv_path)\n",
    "    \n",
    "    print(f\"Loading features: {pt_path}\")\n",
    "    if not os.path.exists(pt_path):\n",
    "        raise FileNotFoundError(f\"{pt_path} not found.\")\n",
    "    features = torch.load(pt_path) \n",
    "    # Usually dataset expects dict or list. If pt_path is the large dict {utt_id: features}, it's fine.\n",
    "    \n",
    "    return features, meta\n",
    "\n",
    "config_path = \"./conf/wce_frame_onset.yaml\"\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, \"r\") as f:\n",
    "        CONFIG = yaml.safe_load(f)\n",
    "    print(f\"Loaded config from {config_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Config file {config_path} not found.\")\n",
    "\n",
    "# Extract Configs\n",
    "DATASET_ARGS = CONFIG.get('dataset_args', {})\n",
    "MODEL_ARGS = CONFIG.get('model_args', {})\n",
    "OPT_CFG = CONFIG.get('optimizer_args', {})\n",
    "SCHEDULER_CFG = CONFIG.get('scheduler_args', {})\n",
    "TRAIN_CFG = CONFIG.get('train_args', {})\n",
    "\n",
    "# Global setting overrides\n",
    "if 'enable_amp' in CONFIG: TRAIN_CFG['enable_amp'] = CONFIG['enable_amp']\n",
    "if 'do_compile' in CONFIG: TRAIN_CFG['do_compile'] = CONFIG['do_compile']\n",
    "\n",
    "# Device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_CFG['device'] = str(device) \n",
    "\n",
    "# Set Seed\n",
    "set_seed(TRAIN_CFG.get('seed', 42))\n",
    "\n",
    "# Load Data\n",
    "# The SpeechCountDataset expects features and meta.\n",
    "# In config: X matches meta csv, y matches feature pt.\n",
    "try:\n",
    "    train_feats, train_meta = load_data_from_args(DATASET_ARGS['X_train'], DATASET_ARGS['y_train'])\n",
    "    valid_feats, valid_meta = load_data_from_args(DATASET_ARGS['X_valid'], DATASET_ARGS['y_valid'])\n",
    "    \n",
    "    target = TRAIN_CFG.get('target_label', 'frame_onset')\n",
    "    \n",
    "    # Initialize Datasets\n",
    "    train_ds = SpeechCountDataset(train_feats, train_meta, target=target)\n",
    "    valid_ds = SpeechCountDataset(valid_feats, valid_meta, target=target)\n",
    "\n",
    "    # 4. DataLoaders\n",
    "    # Apply num-workers and prefetch-factor from config\n",
    "    num_workers = CONFIG.get('num-workers', 0)\n",
    "    prefetch_factor = CONFIG.get('prefetch-factor', 6)\n",
    "    batch_size = TRAIN_CFG.get('batch_size', 256)\n",
    "    \n",
    "    # Adjust prefetch_factor: it requires num_workers > 0\n",
    "    actual_prefetch = prefetch_factor if num_workers > 0 else None\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers, \n",
    "        prefetch_factor=actual_prefetch,\n",
    "        persistent_workers=True\n",
    "        collate_fn=pad_collate_frame_onset,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_ds, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers, \n",
    "        prefetch_factor=actual_prefetch,\n",
    "        persistent_workers=True,\n",
    "        collate_fn=pad_collate_frame_onset,\n",
    "        pin_memory=torch.cuda.is_available()\n",
    "    )\n",
    "\n",
    "    # 5. Model Setup\n",
    "    model = WCEFrameOnset(**MODEL_ARGS)\n",
    "\n",
    "    # Compile if requested\n",
    "    if TRAIN_CFG.get('do_compile', False):\n",
    "        print(\"Compiling model (torch.compile)...\")\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    # 6. Prepare Trainer Args\n",
    "    ARGS = ArgsMock()\n",
    "    ARGS.loss = TRAIN_CFG.get('loss_function', 'frame_bce_mix')\n",
    "\n",
    "    # Update steps\n",
    "    TRAIN_CFG[\"steps_per_epoch\"] = len(train_loader)\n",
    "    TRAIN_CFG[\"total_steps\"] = len(train_loader) * TRAIN_CFG[\"num_epochs\"]\n",
    "    \n",
    "    # Pass scheduler scheme and optimizer name correctly\n",
    "    SCHEDULER_CFG['scheme'] = CONFIG.get('scheduler', 'none')\n",
    "    OPT_CFG['name'] = CONFIG.get('optimize', 'AdamW')\n",
    "    \n",
    "    # 7. Run Training\n",
    "    trainer = Trainer(model, train_loader, valid_loader, ARGS, TRAIN_CFG, OPT_CFG, SCHEDULER_CFG)\n",
    "    trainer.fit(\n",
    "        num_epochs=TRAIN_CFG[\"num_epochs\"], \n",
    "        early_stop_metric=TRAIN_CFG.get(\"monitor_metric\"),\n",
    "        patience=TRAIN_CFG.get(\"early_stopping_window\", 10),\n",
    "        min_delta=TRAIN_CFG.get(\"early_stopping_min_delta\", 0.01)\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during setup: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
